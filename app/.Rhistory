dt = dt[dt[, .(i=.I, level=level-1, child=parent)], on=.(level, i < i), mult='last']
dt = dt[dt[, .(i=.I, level=level-1, child=parent)], on=.(level, (.I) < i), mult='last']
dt = dt[dt[, .(i=.I, level=level-1, child=parent)], .(j=.I), on=.(level, j < i), mult='last']
seq_along(value)
data.table(t=.I)
dt
dt = dt[dt[, .(i=.I, level=level-1, child=parent)], idx:= .I, on=.(level, idx < i), mult='last']
dt = data.table(idx=1:length(value), level, parent=value)
dt = dt[dt[, .(i=.I, level=level-1, child=parent)], on=.(level, idx < i), mult='last']
dt[is.na(parent), parent:= 'ROOT']
dt
dt[, c('idx','level'):= NULL]
x = maketreelist(as.data.frame(dt))
identical(x, my_list)
dt[, .(parent):= NULL]
radialNetwork(my_list)
dt = data.table(idx=1:length(value), level, parent=value)
dt = dt[dt[, .(i=.I, level=level-1, child=parent)], on=.(level, idx < i), mult='last']
dt[is.na(parent), parent:= 'ROOT']
dt[, c('idx','level'):= NULL]
dt
dt = data.table(idx=1:length(value), level, parent=value)
dt = dt[dt[, .(i=idx, level=level-1, child=parent)], on=.(level, idx < i), mult='last']
dt[is.na(parent), parent:= 'ROOT'][, c('idx','level'):= NULL]
dt
dt[parent=='ROOT', parent:= 'root']
x = maketreelist(as.data.frame(dt))
identical(x, my_list)
dt = data.table(idx=1:length(value), level, parent=value)
dt = dt[dt[, .(i=idx, level=level-1, child=parent)], on=.(level, idx < i), mult='last']
dt[is.na(parent), parent:= 'root'][, c('idx','level'):= NULL]
x = maketreelist(as.data.frame(dt))
identical(x, my_list)
rm(list=ls())
level <- c(1, 2, 3, 4, 4, 3, 4, 4, 1, 2, 3)
value <- letters[1:11]
dt = data.table(idx=1:length(value), level, parent=value)
dt
dt = data.table(idx=1:length(value), level, value)
dt
l <- list(g1=as.integer(runif(10,1,10000)),
g2=as.integer(runif(5,1,10000)),
g3=as.integer(runif(5,1,10000)),
g4=as.integer(runif(8,1,10000)))
max.len = max(sapply(l, max))
m = do.call(rbind, lapply(l, function(x) {z = rep(0, max.len); z[x] = 1; z}))
m
l
intsct = m %*% t(m)
rowSums(m)
rowSums(m) %*% t(rowSums(m))
outer( rowSums(m), FUN='+')
outer( rowSums(m), rowSums(m), '+')
union = outer( rowSums(m), rowSums(m), '+') - intsct
union
idx.mat <- t(combn(1:length(l),2))
idx.mat
?fisher.test
intsct
union
?stack
stack(l)
unstack(stack(l))
rm(list=ls())
ma = array(c(8,4,3,1,7,5,9,15,6,10,16,11,2,14,12,13), dim = c(4,4))
ma
data = structure(list(email_address_hash = structure(c(2L, 1L, 1L, 2L
), .Label = c("0004eca7b8bed22aaf4b320ad602505fe9fa9d26", "35c0ef2c2a804b44564fd4278a01ed25afd887f8"
), class = "factor"), open_time = structure(c(2L, 1L, 3L, 4L), .Label = c(" 04:39:24",
" 09:57:20", " 10:39:43", " 19:00:09"), class = "factor")), .Names = c("email_address_hash",
"open_time"), row.names = c(41107L, 47808L, 3973L, 8307L), class = "data.frame")
data
skip_row <- c()
data$hash_time <- rep('NA',NROW(data)) #adding new column to our data
rownames(data) <- as.character(1:NROW(data))
data
seqNum = c(10, 7,  6,  5,  4,  1, 15, 11,  7, 15,  1,  2,  3, 14,  8,  3,  5, 10,  8,  3,  14, 8, 14,  3, 14, 12, 15, 12, 10, 14)
rle(seqNum)
?unsplit
df <- data.frame(id = c(rep(1,7),rep(2,5)), event = c("a","b","b","b","a","b","a","a","a","b","a","a"), time = c(1,3,6,12,24,30,42,1,2,6,17,24))
df.str = lapply(split(df, df$id), function(d) {
z = rep('-', tail(d,1)$time); z[d$time] = as.character(d$event); z })
df.str = lapply(df.str, paste, collapse='')
df.str
df1 = lapply(df.str, function(s) length(gregexpr('(?=a.{1,7}b.{11,17}a)', s, perl=T)[[1]]))
df1
unsplit(df1)
split(df, 'id')
split(df, df$id)
unsplit(df1, names(df1))
do.call(rbind, df1)
df = data.frame(Id=c(0,1,2,3),A=c(1,2,3,4),B=c(5,6,7,8),C=c(9,10,11,NA))
df
expand.grid(df[,2:4])
x = expand.grid(df[,2:4])
apply(x, 1, prod)
rep(df[,1], 3)
df.id = data.frame(id.A=df$id, id.B=df$id, id.C=df$id)
df.id
df.id = data.frame(id.A=df$Id, id.B=df$Id, id.C=df$Id)
expand.grid(df.id)
y = cbind(expand.grid(df.id), apply(df, 1, product))
y = cbind(expand.grid(df.id), apply(df, 1, prod))
y
y = cbind(expand.grid(df.id), apply(x, 1, prod))
y
y = cbind(expand.grid(df.id), prod=apply(x, 1, prod))
y
aggregate( prod ~ I(id.A + id.B + id.C), y)
aggregate( prod ~ I(id.A + id.B + id.C), y, sum)
rm(list=ls())
df = data.frame(Id=c(0,1,2,3),A=c(1,2,3,4),B=c(5,6,7,8),C=c(9,10,11,NA))
df.grid = expand.grid(df[,2:4])
df.id = data.frame(id.A=df$Id, id.B=df$Id, id.C=df$Id)
newdf = cbind(expand.grid(df.id), prod = apply(df.grid,1,prod))
newdf
aggregate( prod ~ id.A + id.B + id.C, newdf, sum)
rep(list(df$id), 3)
rep(list(df$Id), 3)
df
df
cbind(expand.grid(df[,c(1,1,1)], df[,2:4])
)
cbind(expand.grid(df[,c(1,1,1)]), expand.grid(df[,2:4]))
?expand.grid
df.grid = cbind(expand.grid(df[,rep(1,3)]), prod=apply(expand.grid(df[,2:4]), 1, prod))
df.grid
aggregate( prod ~ I(Id + Id.1 + Id.2), df.grid, sum)
aggregate( prod ~ I(id.sum = Id + Id.1 + Id.2), df.grid, sum)
aggregate( prod ~ id.sum=I(Id + Id.1 + Id.2), df.grid, sum)
aggregate( prod ~ I(sum(df.grid[,1:3])), df.grid, sum)
aggregate( prod ~ I(Id + Id.1 + Id.2), df.grid, sum)
df
max(1, min(10, ceiling((1899:1941-1899)/5  + 1)))
pmax(1, pmin(10, ceiling((1899:1941-1899)/5  + 1)))
x = pmax(1, pmin(10, ceiling((1899:1941-1899)/5  + 1)))
setnames(x, 1899:1941)
setNames(x, 1899:1941)
as.Date('1960-01-01') + 17181
as.Date('1960-01-01') + 13102
as.Date('1960-01-01') + 13132
as.Date('1960-01-01') + c(13102,13132,13529,14259,14290,14318,15720,15751,16451,16482,17181,17212)
?predict
?predict.lm
?read.table
read.table(url('http://www.stat.tamu.edu/~sheather/book/docs/datasets/indicators.txt'))
dat = read.table(url('http://www.stat.tamu.edu/~sheather/book/docs/datasets/indicators.txt'), header=T)
model2 = lm(V2 ~ V3, data=dat)
model2 = lm(PriceChange ~ LoanPaymentsOverdue, data=dat)
predict(model2, newdata=4)
predict(model2, newdata=data.frame(LoanPaymentsOverdue=4))
predict(model2, newdata=data.frame(LoanPaymentsOverdue=4), interval='pred')
predict(model2, newdata=data.frame(LoanPaymentsOverdue=4), interval='conf')
dat = read.table(url('http://www.stat.tamu.edu/~sheather/book/docs/datasets/indicators.txt'), header=T)
model2 = lm(PriceChange ~ LoanPaymentsOverdue, data=dat)
predict(model2, newdata=data.frame(LoanPaymentsOverdue=4), interval='conf')
dat = read.table(url('http://www.stat.tamu.edu/~sheather/book/docs/datasets/indicators.txt'), header=T)
model2 = lm(LoanPaymentsOverdue ~ PriceChange, data=dat)
predict(model2, newdata=data.frame(PriceChange=4), interval='conf')
?read.table
da = read.table(url('http://www.census.gov/population/metro/files/lists/historical/99mfips.txt'), header=T, skip=16)
da = read.table(url('http://www.census.gov/population/metro/files/lists/historical/99mfips.txt'), header=F, skip=16)
?read.fwf
da = read.fwf(url('http://www.census.gov/population/metro/files/lists/historical/99mfips.txt'), header=T, skip=16, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49))
da = read.fwf(url('http://www.census.gov/population/metro/files/lists/historical/99mfips.txt'), header=F, skip=16, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49))
head(da)
head(da$V5)
da = read.fwf(url('http://www.census.gov/population/metro/files/lists/historical/99mfips.txt'), header=F, skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49))
head(da)
tail(da)
da = da[,-c(2,4,6,9,11,13)]
head(da)
tail(da)
da = da[!is.na(V1)]
da = da[!is.na(da$V1)]
names(da)
da = da[!is.na(da$V1),]
head(da)
tail(da,20)
tail(da,22)
grep('File', da$V1)
da = head(da, grep('File', da$V1))
da
head(da)
names(da) = c('MSA/CMSA FIPS CODE', 'PMSA FIPS CODE', 'ALT. CMSA FIPS CODE',
'State/County FIPS CODE', 'F', 'City/Town FIPS  CODE', 'Metropolitan Area and Component Names')
head(da)
names(da) = c('MSA/CMSA FIPS CODE', 'PMSA FIPS CODE', 'ALT. CMSA FIPS CODE',
'State FIPS CODE', 'County FIPS CODE', 'F', 'City/Town FIPS CODE',
'Metropolitan Area and Component Names')
names(da) = c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name')
head(da)
da[da==''] = NA
head(da)
da = read.fwf(url('http://www.census.gov/population/metro/files/lists/historical/99mfips.txt'),
header=F, skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49))
da = da[, -c(2,4,6,9,11,13)]
da = da[!is.na(da$V1),]
da = head(da, grep('File', da$V1))
names(da) = c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name')
head(da$PMSA)
da = read.fwf(url('http://www.census.gov/population/metro/files/lists/historical/99mfips.txt'),
header=F, skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49))
da = da[, -c(2,4,6,9,11,13)]
da = da[!is.na(da$V1),]
da = head(da, grep('File', da$V1)-1)
names(da) = c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name')
head(da$PMSA)
tail(da)
da = read.fwf(url('http://www.census.gov/population/metro/files/lists/historical/99mfips.txt'),
header=F, skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
da = da[, -c(2,4,6,9,11,13)]
da = da[!is.na(da$V1),]
da = head(da, grep('File', da$V1)-1)
names(da) = c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name')
head(da$PMSA)
da[grepl('^ *$',da)] = NA
head(da)
head(da$PMSA)
grepl('^ +$', head(da$PMSA))
da[] = lapply(da, function(col) {col[grepl('^ *$',col)] = NA; col})
head(da$PMSA)
head(da)
View(da)
library(stringr)
?str_count
table(nchar(str_extract(da$Name, '^ *')))
da$x = nchar(str_extract(da$Name, '^ *'))
da$Tier = nchar(str_extract(da$Name, '^ *'))
da$Tier = match(da$Tier, unique(da$Tier))
unique(da$Tier)
da$x = NULL
da$Tier = NULL
View(da)
head(da$PMSA)
rm(list=ls())
url = 'http://www.census.gov/population/metro/files/lists/historical/99mfips.txt'
getMSAKey = function(url) {
da = read.fwf(url(url), skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
da = da[, -c(2,4,6,9,11,13)][!is.na(da$V1),][1:(grep('File', da$V1)-1),]
names(da) = c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name')
da[] = lapply(da, function(col) {col[grepl('^ *$',col)] = NA; col})
}
da = getMSAKey(url)
View(da)
getMSAKey = function(url) {
da = read.fwf(url(url), skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
da = da[, -c(2,4,6,9,11,13)]
da = da[!is.na(da$V1),]
da = da[1:(grep('File', da$V1)-1),]
names(da) = c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name')
da[] = lapply(da, function(col) {col[grepl('^ *$',col)] = NA; col})
}
da = getMSAKey(url)
View(da)
is.data.frame(da)
?setDT
library(data.table)
?setDT
getMSAKey = function(url) {
da = read.fwf(url(url), skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
setDT(da)
da = da[, -c(2,4,6,9,11,13)][!is.na(da$V1)][1:(grep('File', da$V1)-1)]
names(da) = c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name')
da[] = lapply(da, function(col) {col[grepl('^ *$',col)] = NA; col})
}
da = getMSAKey(url)
View(da)
da = read.fwf(url(url), skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
setDT(da)
View(da)
da = da[, -c(2,4,6,9,11,13)]
da = read.fwf(url(url), skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
setDT(da)
da = da[, -c(2,4,6,9,11,13)][!is.na(V1)][1:(grep('File',V1)-1)]
View(da)
names(da) = c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name')
rm(url)
keys1 = lapply(urls1, getMSAkey)
keys1 = lapply(urls1, getMSAKey)
urls1 = c(
'http://www.census.gov/population/metro/files/lists/historical/83mfips.txt',
'http://www.census.gov/population/metro/files/lists/historical/90mfips.txt',
'http://www.census.gov/population/metro/files/lists/historical/93mfips.txt',
'http://www.census.gov/population/metro/files/lists/historical/99mfips.txt')
# 2003-2009
urls2 = c(
'http://www.census.gov/population/metro/files/lists/2003/03msa.txt',
'http://www.census.gov/population/metro/files/lists/2003/0312msa.txt',
'http://www.census.gov/population/metro/files/lists/2004/List4.txt',
'http://www.census.gov/population/metro/files/lists/2005/List4.txt',
'http://www.census.gov/population/metro/files/lists/2006/List4.txt',
'http://www.census.gov/population/metro/files/lists/2007/List4.txt',
'http://www.census.gov/population/metro/files/lists/2008/List4.txt',
'http://www.census.gov/population/metro/files/lists/2009/List4.txt')
getMSAKey = function(url) {
da = read.fwf(
url(url), skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
setDT(da)
da = da[, -c(2,4,6,9,11,13)][!is.na(V1)][1:(grep('File',V1)-1)]
setnames(da, c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name'))
da[] = lapply(da, function(col) {col[grepl('^ *$',col)] = NA; col})
}
keys1 = lapply(urls1, getMSAKey)
keys1 = lapply(urls1, getMSAKey)
read.table(url(urls1[1]))
keys1 = list()
for (u in urls1) {
keys1[[u]] = getMSAKey(u)
}
rm(list=ls())
urls1 = c(
'http://www.census.gov/population/metro/files/lists/historical/83mfips.txt',
'http://www.census.gov/population/metro/files/lists/historical/90mfips.txt',
'http://www.census.gov/population/metro/files/lists/historical/93mfips.txt',
'http://www.census.gov/population/metro/files/lists/historical/99mfips.txt')
# 2003-2009
urls2 = c(
'http://www.census.gov/population/metro/files/lists/2003/03msa.txt',
'http://www.census.gov/population/metro/files/lists/2003/0312msa.txt',
'http://www.census.gov/population/metro/files/lists/2004/List4.txt',
'http://www.census.gov/population/metro/files/lists/2005/List4.txt',
'http://www.census.gov/population/metro/files/lists/2006/List4.txt',
'http://www.census.gov/population/metro/files/lists/2007/List4.txt',
'http://www.census.gov/population/metro/files/lists/2008/List4.txt',
'http://www.census.gov/population/metro/files/lists/2009/List4.txt')
getMSAKey = function(url) {
da = read.fwf(
url(url), skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
setDT(da)
da = da[, -c(2,4,6,9,11,13)][!is.na(V1)][1:(grep('File',V1)-1)]
setnames(da, c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name'))
da[] = lapply(da, function(col) {col[grepl('^ *$',col)] = NA; col})
}
keys1 = list()
for (u in urls1) {
keys1[[u]] = getMSAKey(u)
}
keys1
getMSAKey = function(url) {
da = read.fwf(
url(url), skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
setDT(da)
da = da[, -c(2,4,6,9,11,13)][!is.na(V1)][1:(grep('File',V1)-1)]
setnames(da, c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name'))
da[, names(da):= lapply(.SD, function(col) {col[grepl('^ *$',col)] = NA; col}), .SDcols=names(da)]
}
keys1 = list()
for (u in urls1) {
keys1[[u]] = getMSAKey(u)
}
keys1
getMSAKey = function(url) {
da = read.fwf(
url(url), skip=21, widths=c(4,4,4,4,2,6,2,3,3,1,5,5,3,49), stringsAsFactors=F)
setDT(da)
da = da[, -c(2,4,6,9,11,13)][!is.na(V1)][1:(grep('File',V1)-1)]
setnames(da, c('MSA/CMSA','PMSA','ALT. CMSA','State','County','F','City/Town','Name'))
da[, names(da):= lapply(.SD, function(col) {col[grepl('^ *$',col)] = NA; col}), .SDcols=names(da)]
return(da)
}
keys1 = list()
for (u in urls1) {
keys1[[u]] = getMSAKey(u)
}
keys1
?identical
keys1 = lapply(urls1, getMSAKey)
keys1
rm(list=ls())
my.list <- c("035", "566", "60883", "6110", "6752", "6751", "680","681","682","683","684","684",
"685","686", "7048", "70583","7070", "7078", "7079", "7071", "7280", "72886",
"7714", "7715", "7854", "9583", "99662", "99762", "9985")
# Fake data
set.seed(10)
df = as.data.frame(replicate(5, sample(c(my.list, 1e5:(1e5+1000)),10)), stringsAsFactors=FALSE)
df
df$pattern = apply(df, 1, function(i) grep(paste(my.list, collapse="|"), i, value=T))
df
?str_extract
df$pattern = apply(df, 1, function(i) str_extract(paste(my.list, collapse="|"), i))
df$pattern = apply(df, 1, function(i) str_extract(i, paste(my.list, collapse="|")))
df$pattern = apply(df, 1, function(i) str_extract(i, paste(my.list, collapse="|"))[1])
df
unlist(df[1,])
df$pattern = NULL
df$pattern = apply(df, 1, function(i) str_extract(i, paste(my.list, collapse="|"))[1])
df
df$pattern = NULL
str_extract(unlist(df[3,]), paste(my.list, collapse='|'))
Filter(Negate(is.na), str_extract(unlist(df[3,]), paste(my.list, collapse='|')))
apply(df, 1, function(i) Filter(Negate(is.na), str_extract(i, paste(my.list, collapse='|'))))
apply(df, 1, function(i) str_extract(i, paste(my.list, collapse='|')))
apply(df, 1, function(i) str_match(i, paste(my.list, collapse='|')))
apply(df, 1, function(i) str_extract(paste(i), paste(my.list, collapse='|')))
apply(df, 1, function(i) str_extract(paste(i, collapse=','), paste(my.list, collapse='|')))
apply(df, 1, function(i) str_extract(paste(i, collapse=','), my.list))
d
df
rgx = paste(my.list, collapse='|')
df$match = apply(df, 1, function(i) str_extract(paste(i, collapse=','), rgx))
df = df[!is.na(match),]
df
df = subset(df, !is.na(match))
df
?grep
df$match = NULL
df$match = apply(df, 1, function(i) str_extract(paste(i, collapse=','), rgx))
df = subset(df, !is.na(match))
df
df$match
df$V1
rm(list=ls())
15.32/1.83
6033*(1-qnorm(3))
6033*(1-pnorm(3))
structure(list(frucTimePoint = c(NA, NA, "Time Point (min)\a_0\a_10\a_40\a_60\a_80\a_100\a_120\a_140\a_160\a_180\a_", "Time Point (min)\a_0\a_20\a_40\a_60\a_80\a_100\a_120\a_140\a_160\a_180\a_", "Time Point (min)\a_"), frucH2 = c(NA, NA, "H2\r_19\a_5\a_7\a_15\a_21\a_13\a_17\a_12\a_10\a_8\a_", "H2\r_6\a_6\a_11\a_5\a_1\a_2\a_1\a_1\a_2\a_0\a_", "H2\r_")), row.names = c(NA, 5L), .Names = c("frucTimePoint", "frucH2"), class = "data.frame")
install.packages('xgboost')
install.packages('ggplot2')
library(ggplot2)
library(ggrepel)
?ggrepel
devtools::install_github("slowkow/ggrepel")
library(devtools)
install_github("slowkow/ggrepel")
devtools::install_github("slowkow/ggrepel")
library(devtools)
install_github('slowkow/ggrepel')
library(devtools)
install_github('slowkow/ggrepel')
install.packages('Rcpp')
install_github('slowkow/ggrepel')
.libpaths
.libPaths
.libPaths()
library(data.table)
e = .0001
arctan(qnorm(pnorm(e),0,2)/e) - pi()/4
?tan
atan(qnorm(pnorm(e),0,2)/e) - pi()/4
atan(qnorm(pnorm(e),0,2)/e) - pi/4
e = .00001
atan(qnorm(pnorm(e),0,2)/e) - pi/4
atan(qnorm(pnorm(e),0,1:5)/e) - pi/4
atan(qnorm(pnorm(e),0,2:5)/e) - pi/4
(atan(qnorm(pnorm(e),0,2:5)/e) - pi/4) * 360/pi
(atan(qnorm(pnorm(e),0,2:5)/e) - pi/4) * 180/pi
(atan(qnorm(pnorm(e),0,.5)/e) - pi/4) * 180/pi
(atan(qnorm(pnorm(e),0,.5)/e) - pi/4)
setwd('C:/Users/sirallen/Dropbox/FRBR/NIC-structure')
library(rsconnect)
deployApp()
deployApp()
setwd('app')
deployApp()
deployApp()
?deployApp
deployApp(appName='nicStructure')
deployApp(appName='nicStructure')
deployApp(appName='nicStructure')
shiny::runApp()
dir('txt/',full.names=T)
runApp()
if (!file %in% dir('txt/', full.names=T)) { return(NULL) }
runApp()
load_data('1026632, '20161228')
load_data('1026632', '20161228')
load_data('1026632', '2016-12-28')
data = load_data('1026632', '2016-12-28')
nodes = data[[3]]
nodes[, Tier:= min(Tier), by='label']
nodes = unique(nodes[, .(Tier, lat, lng, Loc, label)])
nodes = unname(split(nodes, 1:nrow(nodes)))
links = data[[1]]
links = unique(links[, .(Tier, from.lat, from.lng, to.lat, to.lng)])
links = unname(split(links, 1:nrow(links)))
fromJSON(toJSON(list(nodes, links)))
forceNetwork(
as.data.frame(data[[1]]), as.data.frame(data[[2]]), 'from.id', 'to.id',
NodeID='name', Group='Type', colourScale = JS(ColorScale), zoom=T,
opacity=.8, opacityNoHover=.5, fontSize=10, fontFamily='sans-serif')
load('bhcList.RData')
cc = fread('colorcode.csv')
ColorScale = paste0(
'd3.scale.ordinal().domain([',quoteStr(cc$domain),'])',
'.range([',quoteStr(cc$range),'])')
forceNetwork(
as.data.frame(data[[1]]), as.data.frame(data[[2]]), 'from.id', 'to.id',
NodeID='name', Group='Type', colourScale = JS(ColorScale), zoom=T,
opacity=.8, opacityNoHover=.5, fontSize=10, fontFamily='sans-serif')
library(networkD3)
forceNetwork(
as.data.frame(data[[1]]), as.data.frame(data[[2]]), 'from.id', 'to.id',
NodeID='name', Group='Type', colourScale = JS(ColorScale), zoom=T,
opacity=.8, opacityNoHover=.5, fontSize=10, fontFamily='sans-serif')
?networkD3
JS(ColorScale)
forceNetwork(
as.data.frame(data[[1]]), as.data.frame(data[[2]]), 'from.id', 'to.id',
NodeID='name', Group='Type', zoom=T,
opacity=.8, opacityNoHover=.5, fontSize=10, fontFamily='sans-serif')
deployApp()
forceNetwork(
as.data.frame(data[[1]]), as.data.frame(data[[2]]), 'from.id', 'to.id',
NodeID='name', Group='Type', zoom=T,
opacity=.8, opacityNoHover=.5, fontSize=10, fontFamily='sans-serif')
runApp()
runApp()
runApp('C:/Users/sirallen/Dropbox/FRBR/NIC-structure/_shinyApp.R')
runApp()
runApp()
runApp()
